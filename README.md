# 大規模言語モデル入門

https://gihyo.jp/book/2023/978-4-297-13633-8

## 第1章　はじめに
### 1.1　transformersを使って自然言語処理を解いてみよう
### 1.2　transformersの基本的な使い方
### 1.3　単語埋め込みとニューラルネットワークの基礎
### 1.4　大規模言語モデルとは
## 第2章　Transformer
### 2.1　概要
### 2.2　エンコーダ
### 2.3　エンコーダ・デコーダ
### 2.4　デコーダ
## 第3章　大規模言語モデルの基礎
### 3.1　単語の予測から学習できること
### 3.2　GPT（デコーダ）
### 3.3　BERT・RoBERTa（エンコーダ）
### 3.4　T5（エンコーダ・デコーダ）
### 3.5　多言語モデル
### 3.6　トークナイゼーション
## 第4章　大規模言語モデルの進展
### 4.1　モデルの大規模化とその効果
### 4.2　プロンプトによる言語モデルの制御
### 4.3　アライメントの必要性
### 4.4　指示チューニング
### 4.5　人間のフィードバックからの強化学習
### 4.6　ChatGPT
## 第5章　大規模言語モデルのファインチューニング
### 5.1　日本語ベンチマーク：JGLUE
### 5.2　感情分析モデルの実装
### 5.3　感情分析モデルのエラー分析
### 5.4　自然言語推論・意味的類似度計算・多肢選択式質問応答モデルの実装
### 5.5　メモリ効率の良いファインチューニング
### 5.6　日本語大規模言語モデルの比較
## 第6章　固有表現認識
### 6.1　固有表現認識とは
### 6.2　データセット・前処理・評価指標
### 6.3　固有表現認識モデルの実装
### 6.4　アノテーションツールを用いたデータセット構築
## 第7章　要約生成
### 7.1　要約生成とは
### 7.2　データセット
### 7.3　評価指標
### 7.4　見出し生成モデルの実装
## 第8章　文埋め込み
### 8.1　文埋め込みとは.
### 8.2　文埋め込みモデルSimCSE
### 8.3　文埋め込みモデルの実装
### 8.4　最近傍探索ライブラリFaissを使った検索
## 第9章　質問応答
### 9.1　質問応答システムのしくみ
### 9.2　データセットと評価指標
### 9.3　ChatGPTにクイズを答えさせる
### 9.4　文書検索モデルの実装
### 9.5　文書検索モデルとChatGPTを組み合わせる
